{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kubernetes in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (32.0.1)\n",
      "Requirement already satisfied: tqdm in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (4.67.1)\n",
      "Requirement already satisfied: pandas in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (2.3.0)\n",
      "Requirement already satisfied: nbformat in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (5.10.4)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (from kubernetes) (2025.4.26)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (from kubernetes) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (from kubernetes) (2.9.0.post0)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (from kubernetes) (6.0.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (from kubernetes) (2.40.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (from kubernetes) (1.8.0)\n",
      "Requirement already satisfied: requests in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (from kubernetes) (2.32.3)\n",
      "Requirement already satisfied: requests-oauthlib in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (from kubernetes) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (from kubernetes) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (from kubernetes) (2.4.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (from kubernetes) (0.10)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (from nbformat) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (from nbformat) (4.24.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (from nbformat) (5.8.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (from nbformat) (5.14.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes) (4.9.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat) (0.25.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.3.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (from requests->kubernetes) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (from requests->kubernetes) (3.10)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes) (0.6.1)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /home/arnaud/perso/flink-justin/venv/lib/python3.12/site-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat) (4.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%run ../common/common.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caution: Nodes should have been already in `cluster.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kind delete cluster\n",
      "kind delete cluster\n",
      "Log 0 - 2025-07-09 10:31:05 : Deleting cluster \"kind\" ...\n",
      "Log 0 - 2025-07-09 10:31:11 : Deleted nodes: [\"kind-control-plane\" \"kind-worker\" \"kind-worker3\" \"kind-worker2\"]\n",
      "kind create cluster --config=cluster.yaml\n",
      "kind create cluster --config=cluster.yaml\n",
      "Log 0 - 2025-07-09 10:31:11 : Creating cluster \"kind\" ...\n",
      "Log 0 - 2025-07-09 10:31:11 : ‚Ä¢ Ensuring node image (kindest/node:v1.33.1) üñº  ...\n",
      "Log 0 - 2025-07-09 10:31:11 : ‚úì Ensuring node image (kindest/node:v1.33.1) üñº\n",
      "Log 0 - 2025-07-09 10:31:11 : ‚Ä¢ Preparing nodes üì¶ üì¶ üì¶ üì¶   ...\n",
      "Log 0 - 2025-07-09 10:31:17 : ‚úì Preparing nodes üì¶ üì¶ üì¶ üì¶\n",
      "Log 0 - 2025-07-09 10:31:17 : ‚Ä¢ Writing configuration üìú  ...\n",
      "Log 0 - 2025-07-09 10:31:17 : ‚úì Writing configuration üìú\n",
      "Log 0 - 2025-07-09 10:31:17 : ‚Ä¢ Starting control-plane üïπÔ∏è  ...\n",
      "Log 0 - 2025-07-09 10:31:34 : ‚úì Starting control-plane üïπÔ∏è\n",
      "Log 0 - 2025-07-09 10:31:34 : ‚Ä¢ Installing CNI üîå  ...\n",
      "Log 0 - 2025-07-09 10:31:35 : ‚úì Installing CNI üîå\n",
      "Log 0 - 2025-07-09 10:31:35 : ‚Ä¢ Installing StorageClass üíæ  ...\n",
      "Log 0 - 2025-07-09 10:31:35 : ‚úì Installing StorageClass üíæ\n",
      "Log 0 - 2025-07-09 10:31:35 : ‚Ä¢ Joining worker nodes üöú  ...\n",
      "Log 0 - 2025-07-09 10:31:42 : ‚úì Joining worker nodes üöú\n",
      "Log 0 - 2025-07-09 10:31:43 : Set kubectl context to \"kind-kind\"\n",
      "Log 0 - 2025-07-09 10:31:43 : You can now use your cluster with:\n",
      "Log 0 - 2025-07-09 10:31:43 : \n",
      "Log 0 - 2025-07-09 10:31:43 : kubectl cluster-info --context kind-kind\n",
      "Log 0 - 2025-07-09 10:31:43 : \n",
      "Log 0 - 2025-07-09 10:31:43 : Thanks for using kind! üòä\n",
      "sleep 30\n",
      "sleep 30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_command(\"kind delete cluster\", shell=False)\n",
    "run_command(\"kind create cluster --config=cluster.yaml\", shell=False)\n",
    "run_command(\"sleep 30\", shell=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../common/common_modules.sh\n",
      "../common/common_modules.sh\n",
      "Log 0 - 2025-07-09 10:32:13 : clusterrolebinding.rbac.authorization.k8s.io/manager-full created\n",
      "Log 0 - 2025-07-09 10:32:15 : customresourcedefinition.apiextensions.k8s.io/certificaterequests.cert-manager.io created\n",
      "Log 0 - 2025-07-09 10:32:15 : customresourcedefinition.apiextensions.k8s.io/certificates.cert-manager.io created\n",
      "Log 0 - 2025-07-09 10:32:15 : customresourcedefinition.apiextensions.k8s.io/challenges.acme.cert-manager.io created\n",
      "Log 0 - 2025-07-09 10:32:16 : customresourcedefinition.apiextensions.k8s.io/clusterissuers.cert-manager.io created\n",
      "Log 0 - 2025-07-09 10:32:16 : customresourcedefinition.apiextensions.k8s.io/issuers.cert-manager.io created\n",
      "Log 0 - 2025-07-09 10:32:16 : customresourcedefinition.apiextensions.k8s.io/orders.acme.cert-manager.io created\n",
      "Log 0 - 2025-07-09 10:32:16 : namespace/cert-manager created\n",
      "Log 0 - 2025-07-09 10:32:16 : serviceaccount/cert-manager-cainjector created\n",
      "Log 0 - 2025-07-09 10:32:16 : serviceaccount/cert-manager created\n",
      "Log 0 - 2025-07-09 10:32:16 : serviceaccount/cert-manager-webhook created\n",
      "Log 0 - 2025-07-09 10:32:16 : clusterrole.rbac.authorization.k8s.io/cert-manager-cainjector created\n",
      "Log 0 - 2025-07-09 10:32:16 : clusterrole.rbac.authorization.k8s.io/cert-manager-controller-issuers created\n",
      "Log 0 - 2025-07-09 10:32:16 : clusterrole.rbac.authorization.k8s.io/cert-manager-controller-clusterissuers created\n",
      "Log 0 - 2025-07-09 10:32:16 : clusterrole.rbac.authorization.k8s.io/cert-manager-controller-certificates created\n",
      "Log 0 - 2025-07-09 10:32:16 : clusterrole.rbac.authorization.k8s.io/cert-manager-controller-orders created\n",
      "Log 0 - 2025-07-09 10:32:16 : clusterrole.rbac.authorization.k8s.io/cert-manager-controller-challenges created\n",
      "Log 0 - 2025-07-09 10:32:16 : clusterrole.rbac.authorization.k8s.io/cert-manager-controller-ingress-shim created\n",
      "Log 0 - 2025-07-09 10:32:16 : clusterrole.rbac.authorization.k8s.io/cert-manager-view created\n",
      "Log 0 - 2025-07-09 10:32:16 : clusterrole.rbac.authorization.k8s.io/cert-manager-edit created\n",
      "Log 0 - 2025-07-09 10:32:16 : clusterrole.rbac.authorization.k8s.io/cert-manager-controller-approve:cert-manager-io created\n",
      "Log 0 - 2025-07-09 10:32:16 : clusterrole.rbac.authorization.k8s.io/cert-manager-controller-certificatesigningrequests created\n",
      "Log 0 - 2025-07-09 10:32:16 : clusterrole.rbac.authorization.k8s.io/cert-manager-webhook:subjectaccessreviews created\n",
      "Log 0 - 2025-07-09 10:32:16 : clusterrolebinding.rbac.authorization.k8s.io/cert-manager-cainjector created\n",
      "Log 0 - 2025-07-09 10:32:16 : clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-issuers created\n",
      "Log 0 - 2025-07-09 10:32:16 : clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-clusterissuers created\n",
      "Log 0 - 2025-07-09 10:32:16 : clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-certificates created\n",
      "Log 0 - 2025-07-09 10:32:16 : clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-orders created\n",
      "Log 0 - 2025-07-09 10:32:16 : clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-challenges created\n",
      "Log 0 - 2025-07-09 10:32:16 : clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-ingress-shim created\n",
      "Log 0 - 2025-07-09 10:32:16 : clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-approve:cert-manager-io created\n",
      "Log 0 - 2025-07-09 10:32:16 : clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-certificatesigningrequests created\n",
      "Log 0 - 2025-07-09 10:32:16 : clusterrolebinding.rbac.authorization.k8s.io/cert-manager-webhook:subjectaccessreviews created\n",
      "Log 0 - 2025-07-09 10:32:16 : role.rbac.authorization.k8s.io/cert-manager-cainjector:leaderelection created\n",
      "Log 0 - 2025-07-09 10:32:16 : role.rbac.authorization.k8s.io/cert-manager:leaderelection created\n",
      "Log 0 - 2025-07-09 10:32:16 : role.rbac.authorization.k8s.io/cert-manager-webhook:dynamic-serving created\n",
      "Log 0 - 2025-07-09 10:32:16 : rolebinding.rbac.authorization.k8s.io/cert-manager-cainjector:leaderelection created\n",
      "Log 0 - 2025-07-09 10:32:16 : rolebinding.rbac.authorization.k8s.io/cert-manager:leaderelection created\n",
      "Log 0 - 2025-07-09 10:32:16 : rolebinding.rbac.authorization.k8s.io/cert-manager-webhook:dynamic-serving created\n",
      "Log 0 - 2025-07-09 10:32:16 : service/cert-manager created\n",
      "Log 0 - 2025-07-09 10:32:16 : service/cert-manager-webhook created\n",
      "Log 0 - 2025-07-09 10:32:16 : deployment.apps/cert-manager-cainjector created\n",
      "Log 0 - 2025-07-09 10:32:16 : deployment.apps/cert-manager created\n",
      "Log 0 - 2025-07-09 10:32:16 : deployment.apps/cert-manager-webhook created\n",
      "Log 0 - 2025-07-09 10:32:16 : mutatingwebhookconfiguration.admissionregistration.k8s.io/cert-manager-webhook created\n",
      "Log 0 - 2025-07-09 10:32:16 : validatingwebhookconfiguration.admissionregistration.k8s.io/cert-manager-webhook created\n",
      "Log 0 - 2025-07-09 10:32:16 : Waiting for deployment \"cert-manager-webhook\" rollout to finish: 0 of 1 updated replicas are available...\n",
      "Log 0 - 2025-07-09 10:32:26 : deployment \"cert-manager-webhook\" successfully rolled out\n",
      "Log 0 - 2025-07-09 10:32:27 : namespace/flink-operator-system created\n",
      "Log 0 - 2025-07-09 10:32:28 : customresourcedefinition.apiextensions.k8s.io/flinkclusters.flinkoperator.k8s.io created\n",
      "Log 0 - 2025-07-09 10:32:28 : serviceaccount/flink-operator-controller-manager created\n",
      "Log 0 - 2025-07-09 10:32:28 : role.rbac.authorization.k8s.io/flink-operator-leader-election-role created\n",
      "Log 0 - 2025-07-09 10:32:28 : clusterrole.rbac.authorization.k8s.io/flink-operator-manager-role created\n",
      "Log 0 - 2025-07-09 10:32:28 : clusterrole.rbac.authorization.k8s.io/flink-operator-metrics-reader created\n",
      "Log 0 - 2025-07-09 10:32:28 : clusterrole.rbac.authorization.k8s.io/flink-operator-proxy-role created\n",
      "Log 0 - 2025-07-09 10:32:28 : rolebinding.rbac.authorization.k8s.io/flink-operator-leader-election-rolebinding created\n",
      "Log 0 - 2025-07-09 10:32:28 : clusterrolebinding.rbac.authorization.k8s.io/flink-operator-manager-rolebinding created\n",
      "Log 0 - 2025-07-09 10:32:28 : clusterrolebinding.rbac.authorization.k8s.io/flink-operator-proxy-rolebinding created\n",
      "Log 0 - 2025-07-09 10:32:28 : service/flink-operator-controller-manager-metrics-service created\n",
      "Log 0 - 2025-07-09 10:32:28 : service/flink-operator-webhook-service created\n",
      "Log 0 - 2025-07-09 10:32:28 : deployment.apps/flink-operator-controller-manager created\n",
      "Log 0 - 2025-07-09 10:32:28 : certificate.cert-manager.io/flink-operator-serving-cert created\n",
      "Log 0 - 2025-07-09 10:32:28 : issuer.cert-manager.io/flink-operator-selfsigned-issuer created\n",
      "Log 0 - 2025-07-09 10:32:28 : mutatingwebhookconfiguration.admissionregistration.k8s.io/flink-operator-mutating-webhook-configuration created\n",
      "Log 0 - 2025-07-09 10:32:28 : validatingwebhookconfiguration.admissionregistration.k8s.io/flink-operator-validating-webhook-configuration created\n",
      "Log 0 - 2025-07-09 10:32:28 : namespace/manager created\n",
      "Log 0 - 2025-07-09 10:32:29 : namespace/local-path-storage unchanged\n",
      "Log 0 - 2025-07-09 10:32:29 : serviceaccount/local-path-provisioner-service-account unchanged\n",
      "Log 0 - 2025-07-09 10:32:29 : clusterrole.rbac.authorization.k8s.io/local-path-provisioner-role configured\n",
      "Log 0 - 2025-07-09 10:32:29 : clusterrolebinding.rbac.authorization.k8s.io/local-path-provisioner-bind unchanged\n",
      "Log 0 - 2025-07-09 10:32:29 : deployment.apps/local-path-provisioner configured\n",
      "Log 0 - 2025-07-09 10:32:29 : storageclass.storage.k8s.io/local-path created\n",
      "Log 0 - 2025-07-09 10:32:29 : configmap/local-path-config configured\n",
      "Log 0 - 2025-07-09 10:32:29 : error: the path \"./cm-local-path.yaml\" does not exist\n",
      "Log 0 - 2025-07-09 10:32:59 : \"prometheus-community\" already exists with the same configuration, skipping\n",
      "Log 0 - 2025-07-09 10:32:59 : Hang tight while we grab the latest from your chart repositories...\n",
      "Log 0 - 2025-07-09 10:32:59 : ...Successfully got an update from the \"minio-operator\" chart repository\n",
      "Log 0 - 2025-07-09 10:32:59 : ...Successfully got an update from the \"flink-operator-repo\" chart repository\n",
      "Log 0 - 2025-07-09 10:32:59 : ...Successfully got an update from the \"minio\" chart repository\n",
      "Log 0 - 2025-07-09 10:32:59 : ...Successfully got an update from the \"cloudhut\" chart repository\n",
      "Log 0 - 2025-07-09 10:33:00 : ...Successfully got an update from the \"grafana\" chart repository\n",
      "Log 0 - 2025-07-09 10:33:00 : ...Successfully got an update from the \"prometheus-community\" chart repository\n",
      "Log 0 - 2025-07-09 10:33:00 : Update Complete. ‚éàHappy Helming!‚éà\n",
      "Log 0 - 2025-07-09 10:33:33 : NAME: prom\n",
      "Log 0 - 2025-07-09 10:33:33 : LAST DEPLOYED: Wed Jul  9 10:33:05 2025\n",
      "Log 0 - 2025-07-09 10:33:33 : NAMESPACE: manager\n",
      "Log 0 - 2025-07-09 10:33:33 : STATUS: deployed\n",
      "Log 0 - 2025-07-09 10:33:33 : REVISION: 1\n",
      "Log 0 - 2025-07-09 10:33:33 : NOTES:\n",
      "Log 0 - 2025-07-09 10:33:33 : kube-prometheus-stack has been installed. Check its status by running:\n",
      "Log 0 - 2025-07-09 10:33:33 : kubectl --namespace manager get pods -l \"release=prom\"\n",
      "Log 0 - 2025-07-09 10:33:33 : \n",
      "Log 0 - 2025-07-09 10:33:33 : Visit https://github.com/prometheus-operator/kube-prometheus for instructions on how to create & configure Alertmanager and Prometheus instances using the Operator.\n",
      "Log 0 - 2025-07-09 10:33:33 : podmonitor.monitoring.coreos.com/flink-pod-monitor created\n",
      "Log 0 - 2025-07-09 10:33:33 : \"grafana\" already exists with the same configuration, skipping\n",
      "Log 0 - 2025-07-09 10:33:33 : Hang tight while we grab the latest from your chart repositories...\n",
      "Log 0 - 2025-07-09 10:33:34 : ...Successfully got an update from the \"cloudhut\" chart repository\n",
      "Log 0 - 2025-07-09 10:33:34 : ...Successfully got an update from the \"minio\" chart repository\n",
      "Log 0 - 2025-07-09 10:33:34 : ...Successfully got an update from the \"flink-operator-repo\" chart repository\n",
      "Log 0 - 2025-07-09 10:33:34 : ...Successfully got an update from the \"minio-operator\" chart repository\n",
      "Log 0 - 2025-07-09 10:33:34 : ...Successfully got an update from the \"grafana\" chart repository\n",
      "Log 0 - 2025-07-09 10:33:35 : ...Successfully got an update from the \"prometheus-community\" chart repository\n",
      "Log 0 - 2025-07-09 10:33:35 : Update Complete. ‚éàHappy Helming!‚éà\n",
      "Log 0 - 2025-07-09 10:33:35 : Release \"loki\" does not exist. Installing it now.\n",
      "Log 0 - 2025-07-09 10:33:39 : Error: unable to build kubernetes objects from release manifest: [resource mapping not found for name: \"loki\" namespace: \"\" from \"\": no matches for kind \"PodSecurityPolicy\" in version \"policy/v1beta1\"\n",
      "Log 0 - 2025-07-09 10:33:39 : ensure CRDs are installed first, resource mapping not found for name: \"loki-promtail\" namespace: \"\" from \"\": no matches for kind \"PodSecurityPolicy\" in version \"policy/v1beta1\"\n",
      "Log 0 - 2025-07-09 10:33:39 : ensure CRDs are installed first]\n",
      "Log 0 - 2025-07-09 10:33:49 : \"cloudhut\" already exists with the same configuration, skipping\n",
      "Log 0 - 2025-07-09 10:33:49 : Hang tight while we grab the latest from your chart repositories...\n",
      "Log 0 - 2025-07-09 10:33:49 : ...Successfully got an update from the \"cloudhut\" chart repository\n",
      "Log 0 - 2025-07-09 10:33:49 : ...Successfully got an update from the \"minio\" chart repository\n",
      "Log 0 - 2025-07-09 10:33:49 : ...Successfully got an update from the \"flink-operator-repo\" chart repository\n",
      "Log 0 - 2025-07-09 10:33:49 : ...Successfully got an update from the \"minio-operator\" chart repository\n",
      "Log 0 - 2025-07-09 10:33:50 : ...Successfully got an update from the \"grafana\" chart repository\n",
      "Log 0 - 2025-07-09 10:33:50 : ...Successfully got an update from the \"prometheus-community\" chart repository\n",
      "Log 0 - 2025-07-09 10:33:50 : Update Complete. ‚éàHappy Helming!‚éà\n",
      "Log 0 - 2025-07-09 10:33:50 : Warning: annotation \"kubernetes.io/ingress.class\" is deprecated, please use 'spec.ingressClassName' instead\n",
      "Log 0 - 2025-07-09 10:33:50 : ingress.networking.k8s.io/grafana created\n",
      "Log 0 - 2025-07-09 10:33:50 : ingress.networking.k8s.io/prometheus created\n",
      "Log 0 - 2025-07-09 10:33:50 : ingress.networking.k8s.io/flink created\n",
      "Log 0 - 2025-07-09 10:33:50 : namespace/kafka created\n",
      "Log 0 - 2025-07-09 10:33:52 : Pulled: registry-1.docker.io/bitnamicharts/kafka:32.3.3\n",
      "Log 0 - 2025-07-09 10:33:52 : Digest: sha256:964fd20a39ca56e552c41e6435fa27c4c40c512a81cc10b547d0145087f88b6e\n",
      "Log 0 - 2025-07-09 10:35:26 : NAME: my-release\n",
      "Log 0 - 2025-07-09 10:35:26 : LAST DEPLOYED: Wed Jul  9 10:33:52 2025\n",
      "Log 0 - 2025-07-09 10:35:26 : NAMESPACE: kafka\n",
      "Log 0 - 2025-07-09 10:35:26 : STATUS: deployed\n",
      "Log 0 - 2025-07-09 10:35:26 : REVISION: 1\n",
      "Log 0 - 2025-07-09 10:35:26 : TEST SUITE: None\n",
      "Log 0 - 2025-07-09 10:35:26 : NOTES:\n",
      "Log 0 - 2025-07-09 10:35:26 : CHART NAME: kafka\n",
      "Log 0 - 2025-07-09 10:35:26 : CHART VERSION: 32.3.3\n",
      "Log 0 - 2025-07-09 10:35:26 : APP VERSION: 4.0.0\n",
      "Log 0 - 2025-07-09 10:35:26 : \n",
      "Log 0 - 2025-07-09 10:35:26 : Did you know there are enterprise versions of the Bitnami catalog? For enhanced secure software supply chain features, unlimited pulls from Docker, LTS support, or application customization, see Bitnami Premium or Tanzu Application Catalog. See https://www.arrow.com/globalecs/na/vendors/bitnami for more information.\n",
      "Log 0 - 2025-07-09 10:35:26 : \n",
      "Log 0 - 2025-07-09 10:35:26 : ** Please be patient while the chart is being deployed **\n",
      "Log 0 - 2025-07-09 10:35:26 : \n",
      "Log 0 - 2025-07-09 10:35:26 : Kafka can be accessed by consumers via port 9092 on the following DNS name from within your cluster:\n",
      "Log 0 - 2025-07-09 10:35:26 : \n",
      "Log 0 - 2025-07-09 10:35:26 : my-release-kafka.kafka.svc.cluster.local\n",
      "Log 0 - 2025-07-09 10:35:26 : \n",
      "Log 0 - 2025-07-09 10:35:26 : Each Kafka broker can be accessed by producers via port 9092 on the following DNS name(s) from within your cluster:\n",
      "Log 0 - 2025-07-09 10:35:26 : \n",
      "Log 0 - 2025-07-09 10:35:26 : my-release-kafka-controller-0.my-release-kafka-controller-headless.kafka.svc.cluster.local:9092\n",
      "Log 0 - 2025-07-09 10:35:26 : my-release-kafka-controller-1.my-release-kafka-controller-headless.kafka.svc.cluster.local:9092\n",
      "Log 0 - 2025-07-09 10:35:26 : my-release-kafka-controller-2.my-release-kafka-controller-headless.kafka.svc.cluster.local:9092\n",
      "Log 0 - 2025-07-09 10:35:26 : \n",
      "Log 0 - 2025-07-09 10:35:26 : The CLIENT listener for Kafka client connections from within your cluster have been configured with the following security settings:\n",
      "Log 0 - 2025-07-09 10:35:26 : - SASL authentication\n",
      "Log 0 - 2025-07-09 10:35:26 : \n",
      "Log 0 - 2025-07-09 10:35:26 : To connect a client to your Kafka, you need to create the 'client.properties' configuration files with the content below:\n",
      "Log 0 - 2025-07-09 10:35:26 : \n",
      "Log 0 - 2025-07-09 10:35:26 : security.protocol=SASL_PLAINTEXT\n",
      "Log 0 - 2025-07-09 10:35:26 : sasl.mechanism=SCRAM-SHA-256\n",
      "Log 0 - 2025-07-09 10:35:26 : sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required \\\n",
      "Log 0 - 2025-07-09 10:35:26 : username=\"user1\" \\\n",
      "Log 0 - 2025-07-09 10:35:26 : password=\"$(kubectl get secret my-release-kafka-user-passwords --namespace kafka -o jsonpath='{.data.client-passwords}' | base64 -d | cut -d , -f 1)\";\n",
      "Log 0 - 2025-07-09 10:35:26 : \n",
      "Log 0 - 2025-07-09 10:35:26 : To create a pod that you can use as a Kafka client run the following commands:\n",
      "Log 0 - 2025-07-09 10:35:26 : \n",
      "Log 0 - 2025-07-09 10:35:26 : kubectl run my-release-kafka-client --restart='Never' --image docker.io/bitnami/kafka:4.0.0-debian-12-r8 --namespace kafka --command -- sleep infinity\n",
      "Log 0 - 2025-07-09 10:35:26 : kubectl cp --namespace kafka /path/to/client.properties my-release-kafka-client:/tmp/client.properties\n",
      "Log 0 - 2025-07-09 10:35:26 : kubectl exec --tty -i my-release-kafka-client --namespace kafka -- bash\n",
      "Log 0 - 2025-07-09 10:35:26 : \n",
      "Log 0 - 2025-07-09 10:35:26 : PRODUCER:\n",
      "Log 0 - 2025-07-09 10:35:26 : kafka-console-producer.sh \\\n",
      "Log 0 - 2025-07-09 10:35:26 : --producer.config /tmp/client.properties \\\n",
      "Log 0 - 2025-07-09 10:35:26 : --bootstrap-server my-release-kafka.kafka.svc.cluster.local:9092 \\\n",
      "Log 0 - 2025-07-09 10:35:26 : --topic test\n",
      "Log 0 - 2025-07-09 10:35:26 : \n",
      "Log 0 - 2025-07-09 10:35:26 : CONSUMER:\n",
      "Log 0 - 2025-07-09 10:35:26 : kafka-console-consumer.sh \\\n",
      "Log 0 - 2025-07-09 10:35:26 : --consumer.config /tmp/client.properties \\\n",
      "Log 0 - 2025-07-09 10:35:26 : --bootstrap-server my-release-kafka.kafka.svc.cluster.local:9092 \\\n",
      "Log 0 - 2025-07-09 10:35:26 : --topic test \\\n",
      "Log 0 - 2025-07-09 10:35:26 : --from-beginning\n",
      "Log 0 - 2025-07-09 10:35:26 : \n",
      "Log 0 - 2025-07-09 10:35:26 : WARNING: There are \"resources\" sections in the chart not set. Using \"resourcesPreset\" is not recommended for production. For production installations, please set the following values according to your workload needs:\n",
      "Log 0 - 2025-07-09 10:35:26 : - controller.resources\n",
      "Log 0 - 2025-07-09 10:35:26 : - provisioning.resources\n",
      "Log 0 - 2025-07-09 10:35:26 : - defaultInitContainers.prepareConfig.resources\n",
      "Log 0 - 2025-07-09 10:35:26 : +info https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\n",
      "Log 0 - 2025-07-09 10:35:26 : namespace/ingress-nginx created\n",
      "Log 0 - 2025-07-09 10:35:26 : serviceaccount/ingress-nginx created\n",
      "Log 0 - 2025-07-09 10:35:26 : serviceaccount/ingress-nginx-admission created\n",
      "Log 0 - 2025-07-09 10:35:26 : role.rbac.authorization.k8s.io/ingress-nginx created\n",
      "Log 0 - 2025-07-09 10:35:26 : role.rbac.authorization.k8s.io/ingress-nginx-admission created\n",
      "Log 0 - 2025-07-09 10:35:26 : clusterrole.rbac.authorization.k8s.io/ingress-nginx created\n",
      "Log 0 - 2025-07-09 10:35:26 : clusterrole.rbac.authorization.k8s.io/ingress-nginx-admission created\n",
      "Log 0 - 2025-07-09 10:35:26 : rolebinding.rbac.authorization.k8s.io/ingress-nginx created\n",
      "Log 0 - 2025-07-09 10:35:27 : rolebinding.rbac.authorization.k8s.io/ingress-nginx-admission created\n",
      "Log 0 - 2025-07-09 10:35:27 : clusterrolebinding.rbac.authorization.k8s.io/ingress-nginx created\n",
      "Log 0 - 2025-07-09 10:35:27 : clusterrolebinding.rbac.authorization.k8s.io/ingress-nginx-admission created\n",
      "Log 0 - 2025-07-09 10:35:27 : configmap/ingress-nginx-controller created\n",
      "Log 0 - 2025-07-09 10:35:27 : service/ingress-nginx-controller created\n",
      "Log 0 - 2025-07-09 10:35:27 : service/ingress-nginx-controller-admission created\n",
      "Log 0 - 2025-07-09 10:35:27 : deployment.apps/ingress-nginx-controller created\n",
      "Log 0 - 2025-07-09 10:35:27 : job.batch/ingress-nginx-admission-create created\n",
      "Log 0 - 2025-07-09 10:35:27 : job.batch/ingress-nginx-admission-patch created\n",
      "Log 0 - 2025-07-09 10:35:27 : ingressclass.networking.k8s.io/nginx created\n",
      "Log 0 - 2025-07-09 10:35:27 : validatingwebhookconfiguration.admissionregistration.k8s.io/ingress-nginx-admission created\n",
      "Log 0 - 2025-07-09 10:35:30 : NAME: flink-kubernetes-operator\n",
      "Log 0 - 2025-07-09 10:35:30 : LAST DEPLOYED: Wed Jul  9 10:35:29 2025\n",
      "Log 0 - 2025-07-09 10:35:30 : NAMESPACE: default\n",
      "Log 0 - 2025-07-09 10:35:30 : STATUS: deployed\n",
      "Log 0 - 2025-07-09 10:35:30 : REVISION: 1\n",
      "Log 0 - 2025-07-09 10:35:30 : TEST SUITE: None\n",
      "Log 0 - 2025-07-09 10:35:32 : NAME: operator\n",
      "Log 0 - 2025-07-09 10:35:32 : LAST DEPLOYED: Wed Jul  9 10:35:31 2025\n",
      "Log 0 - 2025-07-09 10:35:32 : NAMESPACE: minio-operator\n",
      "Log 0 - 2025-07-09 10:35:32 : STATUS: deployed\n",
      "Log 0 - 2025-07-09 10:35:32 : REVISION: 1\n",
      "Log 0 - 2025-07-09 10:35:32 : TEST SUITE: None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_command('../common/common_modules.sh')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kind-control-plane\t{'beta.kubernetes.io/arch': 'amd64', 'beta.kubernetes.io/os': 'linux', 'kubernetes.io/arch': 'amd64', 'kubernetes.io/hostname': 'kind-control-plane', 'kubernetes.io/os': 'linux', 'node-role.kubernetes.io/control-plane': '', 'node.kubernetes.io/exclude-from-external-load-balancers': ''}\n",
      "kind-worker\t{'beta.kubernetes.io/arch': 'amd64', 'beta.kubernetes.io/os': 'linux', 'ingress-ready': 'true', 'kubernetes.io/arch': 'amd64', 'kubernetes.io/hostname': 'kind-worker', 'kubernetes.io/os': 'linux', 'tier': 'manager'}\n",
      "kind-worker2\t{'beta.kubernetes.io/arch': 'amd64', 'beta.kubernetes.io/os': 'linux', 'kubernetes.io/arch': 'amd64', 'kubernetes.io/hostname': 'kind-worker2', 'kubernetes.io/os': 'linux', 'tier': 'jobmanager'}\n",
      "kind-worker3\t{'beta.kubernetes.io/arch': 'amd64', 'beta.kubernetes.io/os': 'linux', 'kubernetes.io/arch': 'amd64', 'kubernetes.io/hostname': 'kind-worker3', 'kubernetes.io/os': 'linux', 'tier': 'taskmanager'}\n"
     ]
    }
   ],
   "source": [
    "(manager_node, jobmanager_node, taskmanager_nodes) = get_label_nodes(ip_address=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:             grafana\n",
      "Labels:           <none>\n",
      "Namespace:        manager\n",
      "Address:          localhost\n",
      "Ingress Class:    <none>\n",
      "Default backend:  <default>\n",
      "Rules:\n",
      "  Host                        Path  Backends\n",
      "  ----                        ----  --------\n",
      "  grafana.127-0-0-1.sslip.io  \n",
      "                              /   prom-grafana:80 (10.244.3.4:3000)\n",
      "Annotations:                  kubernetes.io/ingress.class: nginx\n",
      "                              nginx.ingress.kubernetes.io/proxy-body-size: 0\n",
      "Events:\n",
      "  Type    Reason  Age              From                      Message\n",
      "  ----    ------  ----             ----                      -------\n",
      "  Normal  Sync    4s (x2 over 4s)  nginx-ingress-controller  Scheduled for sync\n",
      "\n",
      "\n",
      "Name:             prometheus\n",
      "Labels:           <none>\n",
      "Namespace:        manager\n",
      "Address:          localhost\n",
      "Ingress Class:    <none>\n",
      "Default backend:  <default>\n",
      "Rules:\n",
      "  Host                           Path  Backends\n",
      "  ----                           ----  --------\n",
      "  prometheus.127-0-0-1.sslip.io  \n",
      "                                 /   prom-kube-prometheus-stack-prometheus:9090 (10.244.3.5:9090)\n",
      "Annotations:                     kubernetes.io/ingress.class: nginx\n",
      "                                 nginx.ingress.kubernetes.io/proxy-body-size: 0\n",
      "Events:\n",
      "  Type    Reason  Age              From                      Message\n",
      "  ----    ------  ----             ----                      -------\n",
      "  Normal  Sync    4s (x2 over 4s)  nginx-ingress-controller  Scheduled for sync\n"
     ]
    }
   ],
   "source": [
    "!kubectl describe ing -n manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manager node: 172.18.0.4:30080\n",
      "Access to Minio: http://minio.127-0-0-1.nip.io:30080\n",
      "Access to Grafana: http://grafana.127-0-0-1.nip.io:30080\n",
      "Access to Prometheus: http://prometheus.127-0-0-1:30080\n",
      "Job manager address: 172.18.0.5\n",
      "Task manager addresses: 172.18.0.3\n"
     ]
    }
   ],
   "source": [
    "address = \"127-0-0-1\"\n",
    "print(\"Manager node: {}:30080\".format(manager_node))\n",
    "print(\"Access to Minio: http://minio.{}.nip.io:30080\".format(address))\n",
    "print(\"Access to Grafana: http://grafana.{}.nip.io:30080\".format(address))\n",
    "print(\"Access to Prometheus: http://prometheus.{}:30080\".format(address))\n",
    "print(\"Job manager address: {}\".format(jobmanager_node))\n",
    "print(\"Task manager addresses: {}\".format(taskmanager_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access to Minio: http://172.18.0.4:30900\n",
      "Access to Grafana: http://172.18.0.4:30300\n",
      "Access to Prometheus: http://172.18.0.4:30090\n",
      "Job manager address: 172.18.0.5\n",
      "Task manager addresses: 172.18.0.3\n"
     ]
    }
   ],
   "source": [
    "print(\"Access to Minio: http://{}:30900\".format(manager_node))\n",
    "print(\"Access to Grafana: http://{}:30300\".format(manager_node))\n",
    "print(\"Access to Prometheus: http://{}:30090\".format(manager_node))\n",
    "print(\"Job manager address: {}\".format(jobmanager_node))\n",
    "print(\"Task manager addresses: {}\".format(taskmanager_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import [Flink dashboard](https://grafana.com/grafana/dashboards/14911) in Grafana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../minio/bucket.sh\n",
      "../minio/bucket.sh\n",
      "Log 0 - 2025-07-09 13:11:56 : namespace/minio-tenant unchanged\n",
      "Log 0 - 2025-07-09 13:11:56 : secret/storage-configuration configured\n",
      "Log 0 - 2025-07-09 13:11:56 : secret/storage-user unchanged\n",
      "Log 0 - 2025-07-09 13:11:58 : tenant.minio.min.io/myminio unchanged\n",
      "Log 0 - 2025-07-09 13:12:48 : Forwarding from 127.0.0.1:9000 -> 9000\n",
      "Log 0 - 2025-07-09 13:12:48 : Forwarding from [::1]:9000 -> 9000\n",
      "Log 0 - 2025-07-09 13:12:58 : Handling connection for 9000\n",
      "Log 0 - 2025-07-09 13:12:58 : Added `myminio` successfully.\n",
      "Log 0 - 2025-07-09 13:12:58 : Handling connection for 9000\n",
      "Log 0 - 2025-07-09 13:12:58 : mc: <ERROR> Unable to make bucket `myminio/mybucket`. Your previous request to create the named bucket succeeded and you already own it.\n"
     ]
    }
   ],
   "source": [
    "run_command('../minio/bucket.sh')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
