{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kubernetes in /storage/donatien/.local/lib/python3.8/site-packages (23.3.0)\n",
      "Requirement already satisfied: tqdm in /storage/donatien/.local/lib/python3.8/site-packages (4.64.0)\n",
      "Requirement already satisfied: pandas in /storage/donatien/.local/lib/python3.8/site-packages (1.4.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/lib/python3/dist-packages (from kubernetes) (1.14.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /storage/donatien/.local/lib/python3.8/site-packages (from kubernetes) (1.3.2)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /usr/lib/python3/dist-packages (from kubernetes) (45.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /usr/lib/python3/dist-packages (from kubernetes) (2019.11.28)\n",
      "Requirement already satisfied: requests-oauthlib in /storage/donatien/.local/lib/python3.8/site-packages (from kubernetes) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /storage/donatien/.local/lib/python3.8/site-packages (from kubernetes) (2.8.2)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from kubernetes) (2.22.0)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in /storage/donatien/.local/lib/python3.8/site-packages (from kubernetes) (6.0)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /usr/lib/python3/dist-packages (from kubernetes) (1.25.8)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /storage/donatien/.local/lib/python3.8/site-packages (from kubernetes) (2.6.5)\n",
      "Requirement already satisfied: numpy>=1.18.5; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in /storage/donatien/.local/lib/python3.8/site-packages (from pandas) (1.22.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /storage/donatien/.local/lib/python3.8/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib->kubernetes) (3.1.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth>=1.0.1->kubernetes) (0.2.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /storage/donatien/.local/lib/python3.8/site-packages (from google-auth>=1.0.1->kubernetes) (5.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /storage/donatien/.local/lib/python3.8/site-packages (from google-auth>=1.0.1->kubernetes) (4.8)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth>=1.0.1->kubernetes) (0.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%run ../common/common.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caution: Nodes should have been already in `cluster.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kind delete cluster\n",
      "kind delete cluster\n",
      "Log 0 - 2022-06-14 10:52:38 : Deleting cluster \"kind\" ...\n",
      "kind create cluster --config=cluster.yaml\n",
      "kind create cluster --config=cluster.yaml\n",
      "Log 0 - 2022-06-14 10:52:49 : Creating cluster \"kind\" ...\n",
      "Log 0 - 2022-06-14 10:52:49 : ‚Ä¢ Ensuring node image (kindest/node:v1.23.4) üñº  ...\n",
      "Log 0 - 2022-06-14 10:52:49 : ‚úì Ensuring node image (kindest/node:v1.23.4) üñº\n",
      "Log 0 - 2022-06-14 10:52:49 : ‚Ä¢ Preparing nodes üì¶ üì¶ üì¶ üì¶   ...\n",
      "Log 0 - 2022-06-14 10:53:05 : ‚úì Preparing nodes üì¶ üì¶ üì¶ üì¶\n",
      "Log 0 - 2022-06-14 10:53:06 : ‚Ä¢ Writing configuration üìú  ...\n",
      "Log 0 - 2022-06-14 10:53:07 : ‚úì Writing configuration üìú\n",
      "Log 0 - 2022-06-14 10:53:07 : ‚Ä¢ Starting control-plane üïπÔ∏è  ...\n",
      "Log 0 - 2022-06-14 10:53:23 : ‚úì Starting control-plane üïπÔ∏è\n",
      "Log 0 - 2022-06-14 10:53:23 : ‚Ä¢ Installing CNI üîå  ...\n",
      "Log 0 - 2022-06-14 10:53:25 : ‚úì Installing CNI üîå\n",
      "Log 0 - 2022-06-14 10:53:25 : ‚Ä¢ Installing StorageClass üíæ  ...\n",
      "Log 0 - 2022-06-14 10:53:25 : ‚úì Installing StorageClass üíæ\n",
      "Log 0 - 2022-06-14 10:53:26 : ‚Ä¢ Joining worker nodes üöú  ...\n",
      "Log 0 - 2022-06-14 10:53:52 : ‚úì Joining worker nodes üöú\n",
      "Log 0 - 2022-06-14 10:53:53 : Set kubectl context to \"kind-kind\"\n",
      "Log 0 - 2022-06-14 10:53:53 : You can now use your cluster with:\n",
      "Log 0 - 2022-06-14 10:53:53 : \n",
      "Log 0 - 2022-06-14 10:53:53 : kubectl cluster-info --context kind-kind\n",
      "Log 0 - 2022-06-14 10:53:53 : \n",
      "Log 0 - 2022-06-14 10:53:53 : Thanks for using kind! üòä\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_command(\"kind delete cluster\", shell=False)\n",
    "run_command(\"kind create cluster --config=cluster.yaml\", shell=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../common/common_modules.sh\n",
      "../common/common_modules.sh\n",
      "Log 0 - 2022-06-14 10:53:54 : error: unable to recognize \"./cluster-role-binding-default.yaml\": no matches for kind \"ClusterRoleBinding\" in version \"rbac.authorization.k8s.io/v1beta1\"\n",
      "Log 0 - 2022-06-14 10:53:54 : namespace/ingress-nginx created\n",
      "Log 0 - 2022-06-14 10:53:54 : serviceaccount/ingress-nginx created\n",
      "Log 0 - 2022-06-14 10:53:54 : configmap/ingress-nginx-controller created\n",
      "Log 0 - 2022-06-14 10:53:54 : clusterrole.rbac.authorization.k8s.io/ingress-nginx created\n",
      "Log 0 - 2022-06-14 10:53:54 : clusterrolebinding.rbac.authorization.k8s.io/ingress-nginx created\n",
      "Log 0 - 2022-06-14 10:53:54 : role.rbac.authorization.k8s.io/ingress-nginx created\n",
      "Log 0 - 2022-06-14 10:53:54 : rolebinding.rbac.authorization.k8s.io/ingress-nginx created\n",
      "Log 0 - 2022-06-14 10:53:54 : service/ingress-nginx-controller-admission created\n",
      "Log 0 - 2022-06-14 10:53:54 : service/ingress-nginx-controller created\n",
      "Log 0 - 2022-06-14 10:53:54 : deployment.apps/ingress-nginx-controller created\n",
      "Log 0 - 2022-06-14 10:53:54 : validatingwebhookconfiguration.admissionregistration.k8s.io/ingress-nginx-admission created\n",
      "Log 0 - 2022-06-14 10:53:54 : serviceaccount/ingress-nginx-admission created\n",
      "Log 0 - 2022-06-14 10:53:54 : clusterrole.rbac.authorization.k8s.io/ingress-nginx-admission created\n",
      "Log 0 - 2022-06-14 10:53:54 : clusterrolebinding.rbac.authorization.k8s.io/ingress-nginx-admission created\n",
      "Log 0 - 2022-06-14 10:53:54 : role.rbac.authorization.k8s.io/ingress-nginx-admission created\n",
      "Log 0 - 2022-06-14 10:53:54 : rolebinding.rbac.authorization.k8s.io/ingress-nginx-admission created\n",
      "Log 0 - 2022-06-14 10:53:54 : job.batch/ingress-nginx-admission-create created\n",
      "Log 0 - 2022-06-14 10:53:54 : job.batch/ingress-nginx-admission-patch created\n",
      "Log 0 - 2022-06-14 10:53:55 : clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created\n",
      "Log 0 - 2022-06-14 10:53:55 : clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created\n",
      "Log 0 - 2022-06-14 10:53:55 : rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created\n",
      "Log 0 - 2022-06-14 10:53:55 : serviceaccount/metrics-server created\n",
      "Log 0 - 2022-06-14 10:53:55 : deployment.apps/metrics-server created\n",
      "Log 0 - 2022-06-14 10:53:55 : service/metrics-server created\n",
      "Log 0 - 2022-06-14 10:53:55 : clusterrole.rbac.authorization.k8s.io/system:metrics-server created\n",
      "Log 0 - 2022-06-14 10:53:55 : clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created\n",
      "Log 0 - 2022-06-14 10:53:55 : error: unable to recognize \"https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.3.6/components.yaml\": no matches for kind \"APIService\" in version \"apiregistration.k8s.io/v1beta1\"\n",
      "Log 0 - 2022-06-14 10:53:55 : deployment.apps/metrics-server patched\n",
      "Log 0 - 2022-06-14 10:53:57 : customresourcedefinition.apiextensions.k8s.io/certificaterequests.cert-manager.io created\n",
      "Log 0 - 2022-06-14 10:53:57 : customresourcedefinition.apiextensions.k8s.io/certificates.cert-manager.io created\n",
      "Log 0 - 2022-06-14 10:53:57 : customresourcedefinition.apiextensions.k8s.io/challenges.acme.cert-manager.io created\n",
      "Log 0 - 2022-06-14 10:53:58 : customresourcedefinition.apiextensions.k8s.io/clusterissuers.cert-manager.io created\n",
      "Log 0 - 2022-06-14 10:53:58 : customresourcedefinition.apiextensions.k8s.io/issuers.cert-manager.io created\n",
      "Log 0 - 2022-06-14 10:53:58 : customresourcedefinition.apiextensions.k8s.io/orders.acme.cert-manager.io created\n",
      "Log 0 - 2022-06-14 10:53:58 : namespace/cert-manager created\n",
      "Log 0 - 2022-06-14 10:53:58 : serviceaccount/cert-manager-cainjector created\n",
      "Log 0 - 2022-06-14 10:53:58 : serviceaccount/cert-manager created\n",
      "Log 0 - 2022-06-14 10:53:58 : serviceaccount/cert-manager-webhook created\n",
      "Log 0 - 2022-06-14 10:53:58 : clusterrole.rbac.authorization.k8s.io/cert-manager-cainjector created\n",
      "Log 0 - 2022-06-14 10:53:58 : clusterrole.rbac.authorization.k8s.io/cert-manager-controller-issuers created\n",
      "Log 0 - 2022-06-14 10:53:58 : clusterrole.rbac.authorization.k8s.io/cert-manager-controller-clusterissuers created\n",
      "Log 0 - 2022-06-14 10:53:58 : clusterrole.rbac.authorization.k8s.io/cert-manager-controller-certificates created\n",
      "Log 0 - 2022-06-14 10:53:58 : clusterrole.rbac.authorization.k8s.io/cert-manager-controller-orders created\n",
      "Log 0 - 2022-06-14 10:53:58 : clusterrole.rbac.authorization.k8s.io/cert-manager-controller-challenges created\n",
      "Log 0 - 2022-06-14 10:53:58 : clusterrole.rbac.authorization.k8s.io/cert-manager-controller-ingress-shim created\n",
      "Log 0 - 2022-06-14 10:53:58 : clusterrole.rbac.authorization.k8s.io/cert-manager-view created\n",
      "Log 0 - 2022-06-14 10:53:58 : clusterrole.rbac.authorization.k8s.io/cert-manager-edit created\n",
      "Log 0 - 2022-06-14 10:53:58 : clusterrole.rbac.authorization.k8s.io/cert-manager-controller-approve:cert-manager-io created\n",
      "Log 0 - 2022-06-14 10:53:58 : clusterrole.rbac.authorization.k8s.io/cert-manager-controller-certificatesigningrequests created\n",
      "Log 0 - 2022-06-14 10:53:58 : clusterrole.rbac.authorization.k8s.io/cert-manager-webhook:subjectaccessreviews created\n",
      "Log 0 - 2022-06-14 10:53:58 : clusterrolebinding.rbac.authorization.k8s.io/cert-manager-cainjector created\n",
      "Log 0 - 2022-06-14 10:53:58 : clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-issuers created\n",
      "Log 0 - 2022-06-14 10:53:58 : clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-clusterissuers created\n",
      "Log 0 - 2022-06-14 10:53:58 : clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-certificates created\n",
      "Log 0 - 2022-06-14 10:53:58 : clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-orders created\n",
      "Log 0 - 2022-06-14 10:53:58 : clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-challenges created\n",
      "Log 0 - 2022-06-14 10:53:58 : clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-ingress-shim created\n",
      "Log 0 - 2022-06-14 10:53:58 : clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-approve:cert-manager-io created\n",
      "Log 0 - 2022-06-14 10:53:58 : clusterrolebinding.rbac.authorization.k8s.io/cert-manager-controller-certificatesigningrequests created\n",
      "Log 0 - 2022-06-14 10:53:58 : clusterrolebinding.rbac.authorization.k8s.io/cert-manager-webhook:subjectaccessreviews created\n",
      "Log 0 - 2022-06-14 10:53:58 : role.rbac.authorization.k8s.io/cert-manager-cainjector:leaderelection created\n",
      "Log 0 - 2022-06-14 10:53:58 : role.rbac.authorization.k8s.io/cert-manager:leaderelection created\n",
      "Log 0 - 2022-06-14 10:53:58 : role.rbac.authorization.k8s.io/cert-manager-webhook:dynamic-serving created\n",
      "Log 0 - 2022-06-14 10:53:58 : rolebinding.rbac.authorization.k8s.io/cert-manager-cainjector:leaderelection created\n",
      "Log 0 - 2022-06-14 10:53:58 : rolebinding.rbac.authorization.k8s.io/cert-manager:leaderelection created\n",
      "Log 0 - 2022-06-14 10:53:58 : rolebinding.rbac.authorization.k8s.io/cert-manager-webhook:dynamic-serving created\n",
      "Log 0 - 2022-06-14 10:53:58 : service/cert-manager created\n",
      "Log 0 - 2022-06-14 10:53:58 : service/cert-manager-webhook created\n",
      "Log 0 - 2022-06-14 10:53:58 : deployment.apps/cert-manager-cainjector created\n",
      "Log 0 - 2022-06-14 10:53:58 : deployment.apps/cert-manager created\n",
      "Log 0 - 2022-06-14 10:53:58 : deployment.apps/cert-manager-webhook created\n",
      "Log 0 - 2022-06-14 10:53:58 : mutatingwebhookconfiguration.admissionregistration.k8s.io/cert-manager-webhook created\n",
      "Log 0 - 2022-06-14 10:53:58 : validatingwebhookconfiguration.admissionregistration.k8s.io/cert-manager-webhook created\n",
      "Log 0 - 2022-06-14 10:53:58 : Waiting for deployment \"cert-manager-webhook\" rollout to finish: 0 of 1 updated replicas are available...\n",
      "Log 0 - 2022-06-14 10:54:13 : deployment \"cert-manager-webhook\" successfully rolled out\n",
      "Log 0 - 2022-06-14 10:54:16 : namespace/flink-operator-system created\n",
      "Log 0 - 2022-06-14 10:54:16 : customresourcedefinition.apiextensions.k8s.io/flinkclusters.flinkoperator.k8s.io created\n",
      "Log 0 - 2022-06-14 10:54:16 : serviceaccount/flink-operator-controller-manager created\n",
      "Log 0 - 2022-06-14 10:54:16 : role.rbac.authorization.k8s.io/flink-operator-leader-election-role created\n",
      "Log 0 - 2022-06-14 10:54:16 : clusterrole.rbac.authorization.k8s.io/flink-operator-manager-role created\n",
      "Log 0 - 2022-06-14 10:54:16 : clusterrole.rbac.authorization.k8s.io/flink-operator-metrics-reader created\n",
      "Log 0 - 2022-06-14 10:54:16 : clusterrole.rbac.authorization.k8s.io/flink-operator-proxy-role created\n",
      "Log 0 - 2022-06-14 10:54:16 : rolebinding.rbac.authorization.k8s.io/flink-operator-leader-election-rolebinding created\n",
      "Log 0 - 2022-06-14 10:54:16 : clusterrolebinding.rbac.authorization.k8s.io/flink-operator-manager-rolebinding created\n",
      "Log 0 - 2022-06-14 10:54:16 : clusterrolebinding.rbac.authorization.k8s.io/flink-operator-proxy-rolebinding created\n",
      "Log 0 - 2022-06-14 10:54:16 : service/flink-operator-controller-manager-metrics-service created\n",
      "Log 0 - 2022-06-14 10:54:16 : service/flink-operator-webhook-service created\n",
      "Log 0 - 2022-06-14 10:54:16 : deployment.apps/flink-operator-controller-manager created\n",
      "Log 0 - 2022-06-14 10:54:16 : certificate.cert-manager.io/flink-operator-serving-cert created\n",
      "Log 0 - 2022-06-14 10:54:16 : issuer.cert-manager.io/flink-operator-selfsigned-issuer created\n",
      "Log 0 - 2022-06-14 10:54:16 : mutatingwebhookconfiguration.admissionregistration.k8s.io/flink-operator-mutating-webhook-configuration created\n",
      "Log 0 - 2022-06-14 10:54:16 : validatingwebhookconfiguration.admissionregistration.k8s.io/flink-operator-validating-webhook-configuration created\n",
      "Log 0 - 2022-06-14 10:54:16 : namespace/manager created\n",
      "Log 0 - 2022-06-14 10:54:17 : namespace/local-path-storage unchanged\n",
      "Log 0 - 2022-06-14 10:54:17 : serviceaccount/local-path-provisioner-service-account unchanged\n",
      "Log 0 - 2022-06-14 10:54:17 : clusterrole.rbac.authorization.k8s.io/local-path-provisioner-role configured\n",
      "Log 0 - 2022-06-14 10:54:17 : clusterrolebinding.rbac.authorization.k8s.io/local-path-provisioner-bind unchanged\n",
      "Log 0 - 2022-06-14 10:54:17 : deployment.apps/local-path-provisioner configured\n",
      "Log 0 - 2022-06-14 10:54:17 : storageclass.storage.k8s.io/local-path created\n",
      "Log 0 - 2022-06-14 10:54:17 : configmap/local-path-config configured\n",
      "Log 0 - 2022-06-14 10:54:17 : configmap/local-path-config configured\n",
      "Log 0 - 2022-06-14 10:54:18 : persistentvolumeclaim/pvc-manager-minio created\n",
      "Log 0 - 2022-06-14 10:54:48 : \"minio\" already exists with the same configuration, skipping\n",
      "Log 0 - 2022-06-14 10:54:48 : Hang tight while we grab the latest from your chart repositories...\n",
      "Log 0 - 2022-06-14 10:54:48 : ...Successfully got an update from the \"cloudhut\" chart repository\n",
      "Log 0 - 2022-06-14 10:54:48 : ...Successfully got an update from the \"minio\" chart repository\n",
      "Log 0 - 2022-06-14 10:54:48 : ...Successfully got an update from the \"grafana\" chart repository\n",
      "Log 0 - 2022-06-14 10:54:49 : ...Successfully got an update from the \"prometheus-community\" chart repository\n",
      "Log 0 - 2022-06-14 10:54:49 : Update Complete. ‚éàHappy Helming!‚éà\n",
      "Log 0 - 2022-06-14 10:54:51 : NAME: minio\n",
      "Log 0 - 2022-06-14 10:54:51 : LAST DEPLOYED: Tue Jun 14 10:54:49 2022\n",
      "Log 0 - 2022-06-14 10:54:51 : NAMESPACE: manager\n",
      "Log 0 - 2022-06-14 10:54:51 : STATUS: deployed\n",
      "Log 0 - 2022-06-14 10:54:51 : REVISION: 1\n",
      "Log 0 - 2022-06-14 10:54:51 : TEST SUITE: None\n",
      "Log 0 - 2022-06-14 10:54:51 : NOTES:\n",
      "Log 0 - 2022-06-14 10:54:51 : Minio can be accessed via port 9000 on the following DNS name from within your cluster:\n",
      "Log 0 - 2022-06-14 10:54:51 : minio.manager.svc.cluster.local\n",
      "Log 0 - 2022-06-14 10:54:51 : \n",
      "Log 0 - 2022-06-14 10:54:51 : To access Minio from localhost, run the below commands:\n",
      "Log 0 - 2022-06-14 10:54:51 : \n",
      "Log 0 - 2022-06-14 10:54:51 : 1. export POD_NAME=$(kubectl get pods --namespace manager -l \"release=minio\" -o jsonpath=\"{.items[0].metadata.name}\")\n",
      "Log 0 - 2022-06-14 10:54:51 : \n",
      "Log 0 - 2022-06-14 10:54:51 : 2. kubectl port-forward $POD_NAME 9000 --namespace manager\n",
      "Log 0 - 2022-06-14 10:54:51 : \n",
      "Log 0 - 2022-06-14 10:54:51 : Read more about port forwarding here: http://kubernetes.io/docs/user-guide/kubectl/kubectl_port-forward/\n",
      "Log 0 - 2022-06-14 10:54:51 : \n",
      "Log 0 - 2022-06-14 10:54:51 : You can now access Minio server on http://localhost:9000. Follow the below steps to connect to Minio server with mc client:\n",
      "Log 0 - 2022-06-14 10:54:51 : \n",
      "Log 0 - 2022-06-14 10:54:51 : 1. Download the Minio mc client - https://docs.minio.io/docs/minio-client-quickstart-guide\n",
      "Log 0 - 2022-06-14 10:54:51 : \n",
      "Log 0 - 2022-06-14 10:54:51 : 2. Get the ACCESS_KEY=$(kubectl get secret minio -o jsonpath=\"{.data.accesskey}\" | base64 --decode) and the SECRET_KEY=$(kubectl get secret minio -o jsonpath=\"{.data.secretkey}\" | base64 --decode)\n",
      "Log 0 - 2022-06-14 10:54:51 : \n",
      "Log 0 - 2022-06-14 10:54:51 : 3. mc alias set minio-local http://localhost:9000 \"$ACCESS_KEY\" \"$SECRET_KEY\" --api s3v4\n",
      "Log 0 - 2022-06-14 10:54:51 : \n",
      "Log 0 - 2022-06-14 10:54:51 : 4. mc ls minio-local\n",
      "Log 0 - 2022-06-14 10:54:51 : \n",
      "Log 0 - 2022-06-14 10:54:51 : Alternately, you can use your browser or the Minio SDK to access the server - https://docs.minio.io/categories/17\n",
      "Log 0 - 2022-06-14 10:54:51 : \"prometheus-community\" already exists with the same configuration, skipping\n",
      "Log 0 - 2022-06-14 10:54:51 : Hang tight while we grab the latest from your chart repositories...\n",
      "Log 0 - 2022-06-14 10:54:51 : ...Successfully got an update from the \"minio\" chart repository\n",
      "Log 0 - 2022-06-14 10:54:51 : ...Successfully got an update from the \"cloudhut\" chart repository\n",
      "Log 0 - 2022-06-14 10:54:51 : ...Successfully got an update from the \"grafana\" chart repository\n",
      "Log 0 - 2022-06-14 10:54:51 : ...Successfully got an update from the \"prometheus-community\" chart repository\n",
      "Log 0 - 2022-06-14 10:54:51 : Update Complete. ‚éàHappy Helming!‚éà\n",
      "Log 0 - 2022-06-14 10:55:25 : NAME: prom\n",
      "Log 0 - 2022-06-14 10:55:25 : LAST DEPLOYED: Tue Jun 14 10:54:57 2022\n",
      "Log 0 - 2022-06-14 10:55:25 : NAMESPACE: manager\n",
      "Log 0 - 2022-06-14 10:55:25 : STATUS: deployed\n",
      "Log 0 - 2022-06-14 10:55:25 : REVISION: 1\n",
      "Log 0 - 2022-06-14 10:55:25 : NOTES:\n",
      "Log 0 - 2022-06-14 10:55:25 : kube-prometheus-stack has been installed. Check its status by running:\n",
      "Log 0 - 2022-06-14 10:55:25 : kubectl --namespace manager get pods -l \"release=prom\"\n",
      "Log 0 - 2022-06-14 10:55:25 : \n",
      "Log 0 - 2022-06-14 10:55:25 : Visit https://github.com/prometheus-operator/kube-prometheus for instructions on how to create & configure Alertmanager and Prometheus instances using the Operator.\n",
      "Log 0 - 2022-06-14 10:55:25 : podmonitor.monitoring.coreos.com/flink-pod-monitor created\n",
      "Log 0 - 2022-06-14 10:55:25 : \"grafana\" already exists with the same configuration, skipping\n",
      "Log 0 - 2022-06-14 10:55:25 : Hang tight while we grab the latest from your chart repositories...\n",
      "Log 0 - 2022-06-14 10:55:25 : ...Successfully got an update from the \"cloudhut\" chart repository\n",
      "Log 0 - 2022-06-14 10:55:25 : ...Successfully got an update from the \"minio\" chart repository\n",
      "Log 0 - 2022-06-14 10:55:26 : ...Successfully got an update from the \"grafana\" chart repository\n",
      "Log 0 - 2022-06-14 10:55:26 : ...Successfully got an update from the \"prometheus-community\" chart repository\n",
      "Log 0 - 2022-06-14 10:55:26 : Update Complete. ‚éàHappy Helming!‚éà\n",
      "Log 0 - 2022-06-14 10:55:26 : Release \"loki\" does not exist. Installing it now.\n",
      "Log 0 - 2022-06-14 10:55:28 : W0614 10:55:28.007888   32967 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+\n",
      "Log 0 - 2022-06-14 10:55:28 : W0614 10:55:28.010677   32967 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+\n",
      "Log 0 - 2022-06-14 10:55:28 : W0614 10:55:28.064980   32967 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+\n",
      "Log 0 - 2022-06-14 10:55:28 : W0614 10:55:28.066345   32967 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+\n",
      "Log 0 - 2022-06-14 10:55:28 : NAME: loki\n",
      "Log 0 - 2022-06-14 10:55:28 : LAST DEPLOYED: Tue Jun 14 10:55:27 2022\n",
      "Log 0 - 2022-06-14 10:55:28 : NAMESPACE: manager\n",
      "Log 0 - 2022-06-14 10:55:28 : STATUS: deployed\n",
      "Log 0 - 2022-06-14 10:55:28 : REVISION: 1\n",
      "Log 0 - 2022-06-14 10:55:28 : NOTES:\n",
      "Log 0 - 2022-06-14 10:55:28 : The Loki stack has been deployed to your cluster. Loki can now be added as a datasource in Grafana.\n",
      "Log 0 - 2022-06-14 10:55:28 : \n",
      "Log 0 - 2022-06-14 10:55:28 : See http://docs.grafana.org/features/datasources/loki/ for more detail.\n",
      "Log 0 - 2022-06-14 10:55:38 : namespace/kafka created\n",
      "Log 0 - 2022-06-14 10:55:38 : rolebinding.rbac.authorization.k8s.io/strimzi-cluster-operator-entity-operator-delegation created\n",
      "Log 0 - 2022-06-14 10:55:38 : customresourcedefinition.apiextensions.k8s.io/strimzipodsets.core.strimzi.io created\n",
      "Log 0 - 2022-06-14 10:55:38 : clusterrole.rbac.authorization.k8s.io/strimzi-kafka-client created\n",
      "Log 0 - 2022-06-14 10:55:38 : customresourcedefinition.apiextensions.k8s.io/kafkausers.kafka.strimzi.io created\n",
      "Log 0 - 2022-06-14 10:55:38 : clusterrolebinding.rbac.authorization.k8s.io/strimzi-cluster-operator-kafka-broker-delegation created\n",
      "Log 0 - 2022-06-14 10:55:38 : configmap/strimzi-cluster-operator created\n",
      "Log 0 - 2022-06-14 10:55:38 : customresourcedefinition.apiextensions.k8s.io/kafkas.kafka.strimzi.io created\n",
      "Log 0 - 2022-06-14 10:55:38 : clusterrole.rbac.authorization.k8s.io/strimzi-cluster-operator-namespaced created\n",
      "Log 0 - 2022-06-14 10:55:38 : customresourcedefinition.apiextensions.k8s.io/kafkatopics.kafka.strimzi.io created\n",
      "Log 0 - 2022-06-14 10:55:39 : customresourcedefinition.apiextensions.k8s.io/kafkaconnects.kafka.strimzi.io created\n",
      "Log 0 - 2022-06-14 10:55:39 : customresourcedefinition.apiextensions.k8s.io/kafkabridges.kafka.strimzi.io created\n",
      "Log 0 - 2022-06-14 10:55:39 : customresourcedefinition.apiextensions.k8s.io/kafkaconnectors.kafka.strimzi.io created\n",
      "Log 0 - 2022-06-14 10:55:39 : clusterrole.rbac.authorization.k8s.io/strimzi-entity-operator created\n",
      "Log 0 - 2022-06-14 10:55:39 : clusterrole.rbac.authorization.k8s.io/strimzi-cluster-operator-global created\n",
      "Log 0 - 2022-06-14 10:55:39 : clusterrolebinding.rbac.authorization.k8s.io/strimzi-cluster-operator-kafka-client-delegation created\n",
      "Log 0 - 2022-06-14 10:55:39 : customresourcedefinition.apiextensions.k8s.io/kafkamirrormakers.kafka.strimzi.io created\n",
      "Log 0 - 2022-06-14 10:55:39 : clusterrole.rbac.authorization.k8s.io/strimzi-kafka-broker created\n",
      "Log 0 - 2022-06-14 10:55:39 : customresourcedefinition.apiextensions.k8s.io/kafkamirrormaker2s.kafka.strimzi.io created\n",
      "Log 0 - 2022-06-14 10:55:39 : customresourcedefinition.apiextensions.k8s.io/kafkarebalances.kafka.strimzi.io created\n",
      "Log 0 - 2022-06-14 10:55:39 : serviceaccount/strimzi-cluster-operator created\n",
      "Log 0 - 2022-06-14 10:55:39 : deployment.apps/strimzi-cluster-operator created\n",
      "Log 0 - 2022-06-14 10:55:39 : clusterrolebinding.rbac.authorization.k8s.io/strimzi-cluster-operator created\n",
      "Log 0 - 2022-06-14 10:55:39 : rolebinding.rbac.authorization.k8s.io/strimzi-cluster-operator created\n",
      "Log 0 - 2022-06-14 10:55:39 : \"cloudhut\" already exists with the same configuration, skipping\n",
      "Log 0 - 2022-06-14 10:55:39 : Hang tight while we grab the latest from your chart repositories...\n",
      "Log 0 - 2022-06-14 10:55:39 : ...Successfully got an update from the \"cloudhut\" chart repository\n",
      "Log 0 - 2022-06-14 10:55:39 : ...Successfully got an update from the \"minio\" chart repository\n",
      "Log 0 - 2022-06-14 10:55:39 : ...Successfully got an update from the \"grafana\" chart repository\n",
      "Log 0 - 2022-06-14 10:55:40 : ...Successfully got an update from the \"prometheus-community\" chart repository\n",
      "Log 0 - 2022-06-14 10:55:40 : Update Complete. ‚éàHappy Helming!‚éà\n",
      "Log 0 - 2022-06-14 10:55:40 : ingress.networking.k8s.io/minio created\n",
      "Log 0 - 2022-06-14 10:55:40 : ingress.networking.k8s.io/grafana created\n",
      "Log 0 - 2022-06-14 10:55:40 : ingress.networking.k8s.io/prometheus created\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_command('../common/common_modules.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kind-control-plane\t{'beta.kubernetes.io/arch': 'amd64', 'beta.kubernetes.io/os': 'linux', 'kubernetes.io/arch': 'amd64', 'kubernetes.io/hostname': 'kind-control-plane', 'kubernetes.io/os': 'linux', 'node-role.kubernetes.io/control-plane': '', 'node-role.kubernetes.io/master': '', 'node.kubernetes.io/exclude-from-external-load-balancers': ''}\n",
      "kind-worker\t{'beta.kubernetes.io/arch': 'amd64', 'beta.kubernetes.io/os': 'linux', 'kubernetes.io/arch': 'amd64', 'kubernetes.io/hostname': 'kind-worker', 'kubernetes.io/os': 'linux', 'tier': 'manager'}\n",
      "kind-worker2\t{'beta.kubernetes.io/arch': 'amd64', 'beta.kubernetes.io/os': 'linux', 'kubernetes.io/arch': 'amd64', 'kubernetes.io/hostname': 'kind-worker2', 'kubernetes.io/os': 'linux', 'tier': 'jobmanager'}\n",
      "kind-worker3\t{'beta.kubernetes.io/arch': 'amd64', 'beta.kubernetes.io/os': 'linux', 'kubernetes.io/arch': 'amd64', 'kubernetes.io/hostname': 'kind-worker3', 'kubernetes.io/os': 'linux', 'tier': 'taskmanager'}\n"
     ]
    }
   ],
   "source": [
    "(manager_node, jobmanager_node, taskmanager_nodes) = get_label_nodes(ip_address=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access to Minio: http://172.18.0.5:30900\n",
      "Access to Grafana: http://172.18.0.5:30300\n",
      "Access to Prometheus: http://172.18.0.5:30090\n",
      "Job manager address: 172.18.0.2\n",
      "Task manager addresses: 172.18.0.3\n"
     ]
    }
   ],
   "source": [
    "print(\"Access to Minio: http://{}:30900\".format(manager_node))\n",
    "print(\"Access to Grafana: http://{}:30300\".format(manager_node))\n",
    "print(\"Access to Prometheus: http://{}:30090\".format(manager_node))\n",
    "print(\"Job manager address: {}\".format(jobmanager_node))\n",
    "print(\"Task manager addresses: {}\".format(taskmanager_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_command('mc config host add minio http://172.19.0.5:30900 root rootroot')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
